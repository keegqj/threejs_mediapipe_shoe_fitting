---
title: 4.Mediapipe tutorial
publish: true
---

<ArticleTopAd></ArticleTopAd>

## Mediapipe tutorial

### Official guide

**Docs**:https://developers.google.com/mediapipe
**Manual**:https://developers.google.com/mediapipe/solutions/guide

### Getting started

I installed Mediapipe by `npm install --save @mediapipe/tasks-vision`.
I only use the pose detection to get the landmarks I want.And you should set the running mode as `VIDEO`.
For more imformation, you could visit this website link:https://developers.google.com/mediapipe/solutions/vision/pose_landmarker

### Introduction

- MediaPipe is an open-source, cross-platform framework developed by Google, which allows developers to build machine learning-based applications for various use cases, such as augmented reality, virtual reality, and robotics.
- MediaPipe provides a simple and easy-to-use API for building real-time computer vision and machine learning applications, which can run on multiple platforms, including Android, iOS, web, and desktop.
- MediaPipe supports various pre-built solutions, such as object detection, face detection, hand tracking, pose estimation, and more. It also provides a flexible and extensible architecture, which allows developers to build custom solutions based on their specific needs.
- MediaPipe uses a pipeline-based architecture, which allows developers to easily connect and integrate different components, such as sensors, algorithms, and outputs. It also provides a powerful and efficient engine, which can handle multiple streams of data in real-time, and can be used to build high-performance and scalable applications.
- In summary, MediaPipe is a powerful and versatile framework, which can be used to build various machine learning-based applications, and provides a simple and easy-to-use API, pre-built solutions, and a flexible and extensible architecture.

### Landmarker`s output

The output contains both normalized coordinates (Landmarks) and world coordinates (WorldLandmarks) for each landmark.

The output contains the following normalized coordinates (Landmarks):
- x and y: Landmark coordinates normalized between 0.0 and 1.0 by the image width (x) and height (y).
- z: The landmark depth, with the depth at the midpoint of the hips as the origin. The smaller the value, the closer the landmark is to the camera. The magnitude of z uses roughly the same scale as x.
- visibility: The likelihood of the landmark being visible within the image.

The output contains the following world coordinates (WorldLandmarks):
- x, y, and z: Real-world 3-dimensional coordinates in meters, with the midpoint of the hips as the origin.
- visibility: The likelihood of the landmark being visible within the image.

Reference:https://developers.google.com/mediapipe/solutions/vision/pose_landmarker/web_js

### Problem solution

1. I can`t find a proper solution of transforming and unifying the coordinate system between Threejs and Mediapipe, especially z-axis coordinates.Because the axis in the threejs scene is fixed, while mediapipe's output about the z value changes at any time.
2. Although I have tried my best to binding the shoe model to the human foot identified in the video by using normalized `Landmarks` x,y to locate the identified foot in the video and using `WorldLandmarks` x,y,z to set the shoe model`s rotation and scale, the z-axis coordinates of the shoe model are still not determined. By the way, all the data of landmarks shold be mathematically transformed. 

For details, please refer to `class shoeBinding` .